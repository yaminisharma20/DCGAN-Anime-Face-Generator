{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning torchvision pillow tensorboard\n"
      ],
      "metadata": {
        "id": "OlcMAnDiazLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "HRm6fpUBc4dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/drive/MyDrive/anime_dataset/images\"\n",
        "print(\"Exists:\", os.path.exists(path))\n",
        "print(\"Total images:\", len(os.listdir(path)))\n",
        "print(\"First 5:\", os.listdir(path)[:5])\n"
      ],
      "metadata": {
        "id": "bFP-u_Hac4gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n"
      ],
      "metadata": {
        "id": "L6jv0Gc5c4jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimeDataset(Dataset):\n",
        "    def __init__(self, root_dir, max_images=10000, transform=None):\n",
        "        self.image_paths = sorted(\n",
        "            glob.glob(os.path.join(root_dir, \"*.jpg\"))\n",
        "        )[:max_images]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "B0XZPo6wc4ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = AnimeDataset(\n",
        "    \"/content/drive/MyDrive/anime_dataset/images\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(\"Images loaded:\", len(dataset))\n"
      ],
      "metadata": {
        "id": "4Ls8_UxXc4px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(\"DataLoader ready\")\n"
      ],
      "metadata": {
        "id": "XW6HyZV5c4sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz=100):\n",
        "        super().__init__()\n",
        "        self.nz = nz\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, 512, 4, 1, 0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x.view(x.size(0), self.nz, 1, 1))\n"
      ],
      "metadata": {
        "id": "suRYebqvc4v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 1, 4, 1, 0),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).view(-1)\n"
      ],
      "metadata": {
        "id": "-Ari741xc4y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n"
      ],
      "metadata": {
        "id": "7yN0IsSxc42K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCGAN(pl.LightningModule):\n",
        "    def __init__(self, nz=100):\n",
        "        super().__init__()\n",
        "        self.nz = nz\n",
        "        self.generator = Generator(nz)\n",
        "        self.discriminator = Discriminator()\n",
        "        self.loss = nn.BCELoss()\n",
        "        self.automatic_optimization = False\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        real = batch\n",
        "        bs = real.size(0)\n",
        "        opt_g, opt_d = self.optimizers()\n",
        "\n",
        "        valid = torch.ones(bs, device=self.device)\n",
        "        fake = torch.zeros(bs, device=self.device)\n",
        "\n",
        "        z = torch.randn(bs, self.nz, device=self.device)\n",
        "        fake_imgs = self.generator(z).detach()\n",
        "\n",
        "        d_loss = (self.loss(self.discriminator(real), valid) +\n",
        "                  self.loss(self.discriminator(fake_imgs), fake)) / 2\n",
        "\n",
        "        opt_d.zero_grad()\n",
        "        self.manual_backward(d_loss)\n",
        "        opt_d.step()\n",
        "\n",
        "        z = torch.randn(bs, self.nz, device=self.device)\n",
        "        g_loss = self.loss(self.discriminator(self.generator(z)), valid)\n",
        "\n",
        "        opt_g.zero_grad()\n",
        "        self.manual_backward(g_loss)\n",
        "        opt_g.step()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return [\n",
        "            torch.optim.Adam(self.generator.parameters(), lr=2e-4),\n",
        "            torch.optim.Adam(self.discriminator.parameters(), lr=2e-4)\n",
        "        ]\n"
      ],
      "metadata": {
        "id": "lLBV15_7c45c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DCGAN()\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=5,   # keep small\n",
        "    accelerator=\"cpu\",  # GPU optional\n",
        "    devices=1\n",
        ")\n",
        "\n",
        "trainer.fit(model, data_loader)\n"
      ],
      "metadata": {
        "id": "MoA47Au6c48t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "z = torch.randn(32, 100)\n",
        "with torch.no_grad():\n",
        "    imgs = model.generator(z)\n",
        "\n",
        "imgs = (imgs + 1) / 2\n",
        "grid = vutils.make_grid(imgs, nrow=8)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(grid.permute(1,2,0))\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a8PnHtiIc4_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vutils.save_image(imgs, \"generated_anime_sample.png\", nrow=8)\n",
        "print(\"Saved generated_anime_sample.png\")\n"
      ],
      "metadata": {
        "id": "_gF4axejc5Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=30,        # increase gradually\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "cFa7LW_xc5F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning torchvision pillow\n"
      ],
      "metadata": {
        "id": "WZe7i3uSc5JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "uvifwwHL3fJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "DE0sGYn73fVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimeDataset(Dataset):\n",
        "    def __init__(self, root_dir, max_images=18000, transform=None):\n",
        "        self.image_paths = sorted(\n",
        "            glob.glob(os.path.join(root_dir, \"*.jpg\"))\n",
        "        )[:max_images]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "Gq-SKFPA3fYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = AnimeDataset(\n",
        "    \"/content/drive/MyDrive/anime_dataset/images\",\n",
        "    max_images=18000,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(\"Total images used:\", len(dataset))\n",
        "\n",
        "data_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "KQ0lXR2q3fba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz=100):\n",
        "        super().__init__()\n",
        "        self.nz = nz\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, 512, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x.view(x.size(0), self.nz, 1, 1))\n"
      ],
      "metadata": {
        "id": "bPOhADHo3ffR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).view(-1)\n"
      ],
      "metadata": {
        "id": "DXg1dhZK3fip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCGAN(pl.LightningModule):\n",
        "    def __init__(self, nz=100):\n",
        "        super().__init__()\n",
        "        self.nz = nz\n",
        "        self.generator = Generator(nz)\n",
        "        self.discriminator = Discriminator()\n",
        "        self.loss = nn.BCELoss()\n",
        "        self.automatic_optimization = False\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        real = batch\n",
        "        bs = real.size(0)\n",
        "\n",
        "        opt_g, opt_d = self.optimizers()\n",
        "\n",
        "        valid = torch.ones(bs, device=self.device)\n",
        "        fake = torch.zeros(bs, device=self.device)\n",
        "\n",
        "        # ---- Train Discriminator ----\n",
        "        z = torch.randn(bs, self.nz, device=self.device)\n",
        "        fake_imgs = self.generator(z).detach()\n",
        "\n",
        "        d_loss = (\n",
        "            self.loss(self.discriminator(real), valid) +\n",
        "            self.loss(self.discriminator(fake_imgs), fake)\n",
        "        ) / 2\n",
        "\n",
        "        opt_d.zero_grad()\n",
        "        self.manual_backward(d_loss)\n",
        "        opt_d.step()\n",
        "\n",
        "        # ---- Train Generator ----\n",
        "        z = torch.randn(bs, self.nz, device=self.device)\n",
        "        gen_imgs = self.generator(z)\n",
        "        g_loss = self.loss(self.discriminator(gen_imgs), valid)\n",
        "\n",
        "        opt_g.zero_grad()\n",
        "        self.manual_backward(g_loss)\n",
        "        opt_g.step()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "        return [opt_g, opt_d]\n"
      ],
      "metadata": {
        "id": "Ye6XaHmQ30FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DCGAN()\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=30,          # GOOD quality\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1\n",
        ")\n",
        "\n",
        "trainer.fit(model, data_loader)\n"
      ],
      "metadata": {
        "id": "AyhW-zba30IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.generator.eval()\n",
        "\n",
        "z = torch.randn(32, 100, device=model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    images = model.generator(z)\n",
        "\n",
        "images = (images + 1) / 2\n",
        "grid = vutils.make_grid(images, nrow=8)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(grid.permute(1,2,0).cpu())\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kcUeV-9F30Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vutils.save_image(images, \"final_generated_samples.png\", nrow=8)\n",
        "print(\"Saved final_generated_samples.png\")\n"
      ],
      "metadata": {
        "id": "5olmLcL_30PB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}